{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b39cb75",
   "metadata": {},
   "source": [
    "# Implementation of Convolutional Neural Network in Python\n",
    "Source: https://learnopencv.com/image-classification-using-convolutional-neural-networks-in-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc3876",
   "metadata": {},
   "source": [
    "- Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bf9fb7",
   "metadata": {},
   "source": [
    "Convolutional Neural Network is a Deep Learning algorithm specially designed for working with Images and videos. It takes images as inputs, extracts and learns the features of the image, and classifies them based on the learned features.Idle for medical imaging data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff90e937",
   "metadata": {},
   "source": [
    "# Components of Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f2593",
   "metadata": {},
   "source": [
    "The CNN model works in two steps: feature extraction and Classification\n",
    "\n",
    "Feature Extraction is a phase where various filters and layers are applied to the images to extract the information and features out of it and once it’s done it is passed on to the next phase i.e Classification where they are classified based on the target variable of the problem.\n",
    "\n",
    "A typical CNN model looks like this:\n",
    "\n",
    "- Input layer\n",
    "- Convolution layer + Activation function\n",
    "- Pooling layer\n",
    "- Fully Connected Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf28c6",
   "metadata": {},
   "source": [
    "- *Input layer:*\\\n",
    "    As the name says, it’s our input image and can be Grayscale or RGB. Every image is made up of pixels that range from 0 to 255.\n",
    "    We need to normalize them i.e convert the range between 0 to 1  before passing it to the model.\n",
    "    \n",
    "- *Convolution Layer:*\\\n",
    "    The convolution layer is the layer where the filter is applied to our input image to extract or detect its features.\n",
    "    A filter is applied to the image multiple times and creates a feature map which helps in classifying the input image.\n",
    "    \n",
    "- *Pooling Layer:*\\\n",
    "    The pooling layer is applied after the Convolutional layer and is used to reduce the dimensions of the feature map which helps in preserving the important information or features of the input image and reduces the computation time.\n",
    "    Using pooling, a lower resolution version of input is created that still contains the large or important elements of the input image.The most common types of Pooling are Max Pooling and Average Pooling.\n",
    "    \n",
    "- *Fully Connected Layer:*\\\n",
    "    Till now we have performed the Feature Extraction steps, now comes the Classification part. \n",
    "    The Fully connected layer (as we have in ANN) is used for classifying the input image into a label.\n",
    "    This layer connects the information extracted from the previous steps (i.e Convolution layer and Pooling layers) to the  output layer and eventually classifies the input into the desired label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbfe990",
   "metadata": {},
   "source": [
    "![Schem cnn](schem_cnn.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a477a313",
   "metadata": {},
   "source": [
    "# The Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c46b62",
   "metadata": {},
   "source": [
    "Image classification using CNN Keras – For implementing a CNN, we will stack up Convolutional Layers, followed by Max Pooling layers. We will also include Dropout to avoid overfitting. Finally, we will add a fully connected ( Dense ) layer followed by a softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe20e00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    " \n",
    "def createModel():\n",
    "    model = Sequential()\n",
    "    # The first two layers with 32 filters of window size 3x3\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce4a61e",
   "metadata": {},
   "source": [
    "# Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e625f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the model\n",
    "model1 = createModel()\n",
    " \n",
    "# Set training process params\n",
    "batch_size = 256\n",
    "epochs = 50\n",
    " \n",
    "# Set the training configurations: optimizer, loss function, accuracy metrics\n",
    "model1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "history = model1.fit(train_data,\n",
    "                     train_labels_one_hot,\n",
    "                     batch_size=batch_size, \n",
    "                     epochs=epochs, verbose=1, \n",
    "                     validation_data=(test_data, test_labels_one_hot)\n",
    "          )\n",
    " \n",
    "# Check the model results on the test set\n",
    "model1.evaluate(test_data, test_labels_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97830bd",
   "metadata": {},
   "source": [
    "# Loss & Accuracy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c135cf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves',fontsize=16)\n",
    " \n",
    "# Accuracy Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['accuracy'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_accuracy'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba3477",
   "metadata": {},
   "source": [
    "# Using Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f47e75",
   "metadata": {},
   "source": [
    "One of the major reasons for overfitting is that you don’t have enough data to train your network. Apart from regularization, data augmentation is another very effective way to counter overfitting. It is the process of artificially creating more images from the images you already have by changing the size, orientation etc of the image. \n",
    "\n",
    "It can be a tedious task, but fortunately, this can be done in Keras using the ImageDataGenerator instanceOne of the major reasons for overfitting is that you don’t have enough data to train your network. Apart from regularization, data augmentation is another very effective way to counter overfitting.\n",
    "\n",
    "It is the process of artificially creating more images from the images you already have by changing the size, orientation etc of the image. It can be a tedious task, but fortunately, this can be done in Keras using the ImageDataGenerator instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee58cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "  \n",
    "ImageDataGenerator(\n",
    "    rotation_range=10.,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.,\n",
    "    zoom_range=.1.,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d098fa27",
   "metadata": {},
   "source": [
    "- In the above code, we have provided some of the operations that can be done using the ImageDataGenerator for data augmentation. This includes rotation of the image, shifting the image left/right/top/bottom by some amount, flip the image horizontally or vertically, shear or zoom the image etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43217542",
   "metadata": {},
   "source": [
    "# Training with Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86035dd",
   "metadata": {},
   "source": [
    "Create a model but use data augmentation while training. Also the use ImageDataGenerator to create a generator that will feed the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65937247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "  \n",
    "# Initialize the model\n",
    "model2 = createModel()\n",
    " \n",
    "model2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "# Set training process params\n",
    "batch_size = 256\n",
    "epochs = 50\n",
    " \n",
    "# Define transformations for train data\n",
    "datagen = ImageDataGenerator(\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    " \n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "history2 = model2.fit(datagen.flow(train_data, train_labels_one_hot, batch_size=batch_size),\n",
    "                      steps_per_epoch=int(np.ceil(train_data.shape[0] / float(batch_size))),\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(test_data, test_labels_one_hot),\n",
    "                      workers=4\n",
    "           )\n",
    " \n",
    "model2.evaluate(test_data, test_labels_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e6f2cf",
   "metadata": {},
   "source": [
    "From the above:\\\n",
    "The creation of the model and configure it.\n",
    "Then creating an ImageDataGenerator object and configure it using parameters for horizontal flip, and image translation.\n",
    "The datagen.flow() function generates batches of data after performing the data transformations/augmentation specified during the instantiation of the data generator.\n",
    "The fit_generator function will train the model using the data obtained in batches from the datagen.flow function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c7334b",
   "metadata": {},
   "source": [
    "# Loss & Accuracy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c2f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history2.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history2.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves',fontsize=16)\n",
    " \n",
    "# Accuracy Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history2.history['accuracy'],'r',linewidth=3.0)\n",
    "plt.plot(history2.history['val_accuracy'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8577da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff590f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
